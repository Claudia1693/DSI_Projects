{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset and parsing/cleaning of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('mycareersfuture_master.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the salary columns\n",
    "\n",
    "# Remove dollar sign and comma\n",
    "for col in ['SalaryLower', 'SalaryUpper']:\n",
    "    data[col] = [re.sub('[$,]', '', text) for text in data[col]]\n",
    "    \n",
    "# Extracting the text and placing into a new column 'SalaryType\n",
    "data['SalaryType'] = data['SalaryUpper'].apply(lambda x: re.search('\\D+', x).group())\n",
    "\n",
    "# Extracting only the numerical value for the SalaryUpper column\n",
    "data['SalaryUpper'] = data['SalaryUpper'].apply(lambda x: re.match('\\d*', x).group())\n",
    "\n",
    "# Replacing the text 'Salary undisclosed' with NaN\n",
    "data[['SalaryLower', 'SalaryType']] = data[['SalaryLower', 'SalaryType']].replace('Salary undisclosed', np.nan)\n",
    "\n",
    "# Replacing '' in SalaryUpper with NaN\n",
    "data['SalaryUpper'] = data['SalaryUpper'].replace('', np.nan)\n",
    "\n",
    "# Set the salary columns to numeric\n",
    "data[['SalaryLower', 'SalaryUpper']] = data[['SalaryLower', 'SalaryUpper']].astype('float32')\n",
    "\n",
    "# Convert the annual salary data into monthly salary data\n",
    "data.loc[data['SalaryType']=='Annually', ['SalaryLower', 'SalaryUpper']] = \\\n",
    "data[data['SalaryType']=='Annually'][['SalaryLower', 'SalaryUpper']].apply(lambda x: x/12)\n",
    "\n",
    "# Update the SalaryType to monthly\n",
    "data.loc[data['SalaryType']=='Annually', 'SalaryType'] = 'Monthly'\n",
    "\n",
    "# Create SalaryMean which is the mean of SalaryLower and SalaryUpper\n",
    "data['SalaryMean'] = (data['SalaryLower'] + data['SalaryUpper']) / 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['EmploymentType'].value_counts()\n",
    "\n",
    "# Exclude all those job listings that are temporary, freelance, internship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of those Employment Types to drop\n",
    "emp_type_list = data['EmploymentType'].value_counts().index[7::]\n",
    "\n",
    "# Iterate through each Employment Type and exclude them\n",
    "for emp_type in emp_type_list:\n",
    "    data = data[data['EmploymentType'] != emp_type].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine RoleDesc and Requirements\n",
    "data['JD'] = data['RoleDesc'] + ' ' + data['Requirements']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse dummy variables for columns, JobCategories, EmploymentType, Seniority\n",
    "col_list = ['JobCategories', 'EmploymentType', 'Seniority']\n",
    "\n",
    "for col in col_list:\n",
    "    value_list = data[col].unique()\n",
    "    value_list = [value.split(',') for value in value_list]\n",
    "    value_list = list(itertools.chain(*value_list))\n",
    "    value_list = [str.strip(value) for value in value_list]\n",
    "    value_list = np.unique(value_list)\n",
    "    \n",
    "    # Create dummy variables for the column\n",
    "    for value in value_list:\n",
    "        data.loc[data[col].str.contains(value), value] = 1\n",
    "        \n",
    "    # Replace NaN with zero\n",
    "    data[value_list] = data[value_list].fillna(value=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the distribution of SalaryMean\n",
    "fig = plt.figure(figsize=(18,6))\n",
    "ax1 = fig.add_subplot(121)\n",
    "data['SalaryMean'].hist(ax=ax1, bins=15)\n",
    "ax2 = fig.add_subplot(122)\n",
    "data.boxplot(column='SalaryMean', ax=ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data[~data['SalaryMean'].isnull()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As the distribution of salary is right skewed with a long right tail,\n",
    "# classify the salary into 2 groups - Above Median (1) and Median and Below (0) \n",
    "\n",
    "data1['SalaryLabel'] = data1['SalaryMean'].apply(lambda x: 1 if x > data1['SalaryMean'].median() else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check correlation of dummy variables with target\n",
    "\n",
    "sector_var = pd.concat([data1.iloc[:,15:47].copy(), data1['SalaryLabel']], axis=1)\n",
    "emptype_var = pd.concat([data1.iloc[:,47:50].copy(), data1['SalaryLabel']], axis=1)\n",
    "senior_var = pd.concat([data1.iloc[:,50::].copy(), data1['SalaryLabel']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,6))\n",
    "sns.heatmap(senior_var.corr(), annot=True)\n",
    "\n",
    "# the seniority features have little correlation with the target variable SalaryLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,6))\n",
    "sns.heatmap(emptype_var.corr(), annot=True)\n",
    "\n",
    "# the EmploymentType features have little correlation with the target variable SalaryLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sector_corr = sector_var.corr()\n",
    "print sector_corr.iloc[:, -1]\n",
    "\n",
    "# the sector features have little correlation with the target variable SalaryLabel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence for the prediction of classification labels of salary, use only the job description  \n",
    "and job requirements and discard the other features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up predictor and target varibles plus split data for train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy JD column to as x variable, SalaryLabel as y\n",
    "\n",
    "x = data1['JD'].copy()\n",
    "y = data1['SalaryLabel'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline accuracy\n",
    "print(1. - y.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=29)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try first model of LogisticRegression to predict if the salary of a job posting will be above median or below median  \n",
    "Use Logistic Regression as it is the most simple yet powerful classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First model of Logistic Regression\n",
    "\n",
    "# Tokenise the x_train which is job description and job requirements\n",
    "cvt = CountVectorizer(ngram_range=(1,4))\n",
    "tokens_train = pd.DataFrame(cvt.fit_transform(x_train).todense(), columns=cvt.get_feature_names())\n",
    "\n",
    "# Tokenise the x_test using the same trained CountVectorizer\n",
    "tokens_test = pd.DataFrame(cvt.transform(x_test).todense(), columns=cvt.get_feature_names())\n",
    "\n",
    "lr = LogisticRegression(random_state=29)\n",
    "lr.fit(tokens_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validate the Logistic Regression model\n",
    "scores = cross_val_score(lr, tokens_train, y_train, cv=5, n_jobs=-1, verbose=1)\n",
    "print('Cross validation score: {}'.format(scores))\n",
    "print('Mean score: {}'.format(np.mean(scores)))\n",
    "\n",
    "# Score on test data\n",
    "print('Score on test data: {}'.format(lr.score(tokens_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning of LogisticRegression model for better results\n",
    "params = {\n",
    "    'C' : [0.2, 0.4, 0.6, 0.8, 1.0],\n",
    "    'solver' : ['newton-cg', 'lbfgs', 'sag']\n",
    "}\n",
    "\n",
    "lr_gs = GridSearchCV(lr, param_grid=params, cv=3, n_jobs=-1, verbose=1)\n",
    "lr_gs.fit(tokens_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second model of RandomForest\n",
    "rfc = RandomForestClassifier(n_jobs=-1, random_state=29, verbose=1)\n",
    "rfc.fit(tokens_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validate the RandomForest model\n",
    "scores = cross_val_score(salary_pipe, x_train, y_train, cv=5, n_jobs=-1)\n",
    "print('Cross validation score: {}'.format(scores))\n",
    "print('Mean score: {}'.format(np.mean(scores)))\n",
    "\n",
    "# Score on test data\n",
    "print('Score on test data: {}'.format(salary_pipe.score(x_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning of RandomForest model for better results\n",
    "params = {\n",
    "    'n_estimators' : range(1 , 11, 2),\n",
    "    'criterion' : ['gini', 'entropy'],\n",
    "    'max_depth' : [1, 2, 3, None]\n",
    "}\n",
    "\n",
    "rf_gs = GridSearchCV(RandomForestClassifier(random_state=29), param_grid=params, cv=3, n_jobs=-1)\n",
    "rf_gs.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "Set up the target variable as IT sector versus non-IT sector jobs and build a classification model  \n",
    "to predict it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up y variable to the binary column \"Information Technology\"\n",
    "y_2 = data['Information Technology'].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title_list = ['analyst', 'manager', 'consultant', 'fellow', 'specialist', 'director', 'designer',\\\n",
    "                  'lead', 'avp', 'vp', 'svp', 'developer', 'assistant', 'junior', 'engineer', 'scientist', \\\n",
    "                  'software', 'head', 'architect', 'chief', 'officer', 'administrator', 'executive', 'deputy']\n",
    "\n",
    "snr_list = ['senior', 'snr', 'sr']\n",
    "ass_list = ['assoc', 'associate']\n",
    "research = ['research', 'researcher']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['JobTitle'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns not required \n",
    "col_drop_list =['Company', 'SalaryLower', 'SalaryUpper', 'OfficeLocation', 'EmploymentType', 'Seniority',\\\n",
    "                'JobCategories', 'RoleDesc', 'Requirements', 'mcfURL', 'SalaryType', 'no information'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_cat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['JobCategories'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['mcfURL', 'SalaryType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis 1:  \n",
    "Build a linear regression model to predict the mean salary value  \n",
    "\n",
    "Attempt 1 : Used job title to predict salary -> Result was bad, model does not predict well at all  \n",
    "\n",
    "### Hypothesis 2:  \n",
    "Build a classification model to predict the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis 1: predict salary\n",
    "\n",
    "# merge job description and job requirement together\n",
    "x_data = df['job_description'] + df['job_requirement']\n",
    "\n",
    "# tokenise job title separately\n",
    "title_data = df['job_title'].copy()\n",
    "\n",
    "# set up target variable\n",
    "y = df['salary_mean'].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenise job details\n",
    "cvt = CountVectorizer(ngram_range=(1,4), stop_words=stop_words)\n",
    "tokens = pd.DataFrame(cvt.fit_transform(x_data).todense(), columns=cvt.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum by columns and then sort by descending order to get the top 10 occuring word/n_gram\n",
    "token_count = tokens.sum(axis=0).sort_values(ascending=False)\n",
    "token_count.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and test data\n",
    "x_train, x_test, y_train, y_test = train_test_split(tokens, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(x_train, y_train)\n",
    "print('Cross val score: {}'.format(np.mean(cross_val_score(lr, x_train, y_train, cv=3, n_jobs=-1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenise job description and job requirement\n",
    "cvt = CountVectorizer(ngram_range=(1,4), min_df=0.1, max_df=0.9)\n",
    "\n",
    "cvt.fit(x_data)\n",
    "x_tokens = pd.DataFrame(cvt.transform(x_data).todense(), columns=cvt.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum to see which are the top occurences\n",
    "phrase_count = x_tokens.sum(axis=0).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Philly's dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_philly = pd.read_csv('jobs_900.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_philly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ph = df_philly.sample(n=650, axis=0, random_state=29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ph.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ph.iloc[145,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda2]",
   "language": "python",
   "name": "conda-env-anaconda2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
